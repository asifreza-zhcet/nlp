{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f035b6",
   "metadata": {},
   "source": [
    "# Bag of words 3 april"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b28b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph =  \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614753d",
   "metadata": {},
   "source": [
    "## Text cleaning, stemming, stopwords removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7b84be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india.',\n",
       " 'year history people world come invaded u captured land conquered minds.',\n",
       " 'alexander onwards greek turk mogul portuguese british french dutch came looted u took ours.',\n",
       " 'yet done nation.',\n",
       " 'conquered anyone.',\n",
       " 'grabbed land culture history tried enforce way life them.',\n",
       " '',\n",
       " 'respect freedom others.that first vision freedom.',\n",
       " 'believe india got first vision started war independence.',\n",
       " 'freedom must protect nurture build on.',\n",
       " 'free one respect us.',\n",
       " 'second vision india development.',\n",
       " 'fifty year developing nation.',\n",
       " 'time see developed nation.',\n",
       " 'among top nation world term gdp.',\n",
       " 'percent growth rate areas.',\n",
       " 'poverty level falling.',\n",
       " 'achievement globally recognised today.',\n",
       " 'yet lack self confidence see developed nation self reliant self assured.',\n",
       " 'incorrect',\n",
       " 'third vision.',\n",
       " 'india must stand world.',\n",
       " 'believe unless india stand world one respect us.',\n",
       " 'strength respect strength.',\n",
       " 'must strong military power also economic power.',\n",
       " 'must go hand hand.',\n",
       " 'good fortune worked three great minds.',\n",
       " 'dr. vikram sarabhai dept.',\n",
       " 'space professor satish dhawan succeeded dr. brahm prakash father nuclear material.',\n",
       " 'lucky worked three closely consider great opportunity life.',\n",
       " 'see four milestone career']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "lm = WordNetLemmatizer()\n",
    "corpus = []\n",
    "sentences = sent_tokenize(paragraph)\n",
    "for sentence in sentences:\n",
    "    review = re.sub(r'[^a-zA-Z.]+',' ', sentence).lower()\n",
    "    review = review.split()\n",
    "    review = [lm.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf9ef0",
   "metadata": {},
   "source": [
    "### Applying Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7c80bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc4d74",
   "metadata": {},
   "source": [
    "### Applying Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5dc540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.25883507, 0.30512561,\n",
       "        0.        ],\n",
       "       [0.        , 0.2773501 , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()\n",
    "X_tf = tf.fit_transform(corpus).toarray()\n",
    "X_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a74f2f",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aa2a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "new_corpus = [word_tokenize(sentence) for sentence in corpus]\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(new_corpus, min_count=1)\n",
    "#if the word is present < then 1 then use to skip the  conunt and as my data is very small \n",
    "#word2vec is applied for huge amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa3e7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00778156, -0.0067647 , -0.00314586,  0.00661998, -0.00083862,\n",
       "        0.00885579, -0.0022869 , -0.00527606,  0.00391204,  0.00219418,\n",
       "       -0.00028644, -0.00247473, -0.00601351,  0.0040706 , -0.00761856,\n",
       "       -0.00891593, -0.00915735,  0.00838806,  0.00399032,  0.00709481,\n",
       "        0.00991447, -0.00722987,  0.00404161,  0.00280477,  0.00616385,\n",
       "       -0.003396  ,  0.00931382, -0.00580054,  0.00703017,  0.00694239,\n",
       "       -0.00038915,  0.00506917,  0.00667078,  0.00151696,  0.00735391,\n",
       "        0.00241414, -0.00150715,  0.00740738,  0.00469352, -0.0031889 ,\n",
       "        0.00166394, -0.0001386 ,  0.00495837, -0.00543187, -0.00416714,\n",
       "       -0.00092253,  0.00380693, -0.00657267,  0.0078624 , -0.00308292,\n",
       "        0.0057371 ,  0.00283747,  0.00682438, -0.0044562 , -0.00321379,\n",
       "        0.00306628, -0.00277081,  0.00593644, -0.00595266,  0.00259767,\n",
       "       -0.00070224, -0.00061544,  0.00252959, -0.00218281, -0.00424451,\n",
       "       -0.00855882,  0.00247926,  0.00534004, -0.00588124,  0.00912972,\n",
       "        0.0040211 , -0.00517302, -0.00126822,  0.00393469, -0.00698196,\n",
       "        0.00204778,  0.00550365,  0.00625075,  0.00541269,  0.00366073,\n",
       "       -0.00274955, -0.00608217,  0.00813109, -0.00727892, -0.00164633,\n",
       "       -0.00326634,  0.00652032, -0.00628903,  0.00338389,  0.00205179,\n",
       "       -0.00404743, -0.00823228, -0.00803161,  0.00352263, -0.009551  ,\n",
       "        0.00574757, -0.00293605, -0.00915983, -0.00514855,  0.00774234],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding Word Vectors\n",
    "vector = model.wv['war']\n",
    "#if i want to find the vector of war word and if i want to find the relationship \n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7de475e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brahm', 0.23387396335601807),\n",
       " ('dhawan', 0.21503275632858276),\n",
       " ('term', 0.21360917389392853),\n",
       " ('must', 0.19552014768123627),\n",
       " ('incorrect', 0.15426145493984222),\n",
       " ('french', 0.13639995455741882),\n",
       " ('among', 0.12909086048603058),\n",
       " ('dr.', 0.12036918103694916),\n",
       " ('four', 0.10741925239562988),\n",
       " ('prakash', 0.10618045926094055)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most similar words\n",
    "model.wv.most_similar('war')\n",
    "#if i try to find most similar word related to the war "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1878cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('build', 0.2688697874546051),\n",
       " ('confidence', 0.20910266041755676),\n",
       " ('developing', 0.1775529682636261),\n",
       " ('vikram', 0.1541260927915573),\n",
       " ('invaded', 0.1430463194847107),\n",
       " ('career', 0.130289688706398),\n",
       " ('strength', 0.12817755341529846),\n",
       " ('recognised', 0.12560154497623444),\n",
       " ('lack', 0.11839273571968079),\n",
       " ('areas', 0.11378474533557892)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('freedom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b4b3ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recognised', 0.29878243803977966),\n",
       " ('us', 0.18266820907592773),\n",
       " ('fifty', 0.15772563219070435),\n",
       " ('freedom', 0.1541261225938797),\n",
       " ('british', 0.14964725077152252),\n",
       " ('great', 0.14674432575702667),\n",
       " ('growth', 0.14438821375370026),\n",
       " ('professor', 0.13428857922554016),\n",
       " ('go', 0.13385987281799316),\n",
       " ('invaded', 0.12830732762813568)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('vikram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd700fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
